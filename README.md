# ğŸ Bee Detection - Mobile Edge AI POC

Ce projet est un **Proof of Concept (POC)** visant Ã  dÃ©tecter des abeilles en temps rÃ©el sur des appareils mobiles Android. 

L'objectif est de crÃ©er une solution **Edge AI** (intelligence artificielle embarquÃ©e) capable de fonctionner **sans connexion internet**, en utilisant un modÃ¨le de vision par ordinateur optimisÃ© pour les contraintes matÃ©rielles (batterie, chauffe, latence).

---

## ğŸ— Architecture & Workflow

Le projet suit un pipeline en 3 Ã©tapes principales. Actuellement, nous sommes Ã  l'**Ã‰tape 1**.

1.  **ğŸ§  EntraÃ®nement (ML Pipeline)** :
    *   PrÃ©paration du dataset.
    *   Fine-tuning du modÃ¨le **YOLOv8 Nano** (le plus lÃ©ger).
    *   Validation des performances (mAP).
2.  **âš™ï¸ Conversion & Optimisation** *(Ã€ venir)* :
    *   Exportation du modÃ¨le vers **TensorFlow Lite (.tflite)**.
    *   Quantification (Float16 ou INT8) pour l'accÃ©lÃ©ration NPU/GPU mobile.
3.  **ğŸ“± IntÃ©gration Android** *(Ã€ venir)* :
    *   DÃ©veloppement d'une app native (Kotlin + Jetpack Compose).
    *   IntÃ©gration du runtime **LiteRT** (ex-TFLite) et CameraX.

---

## ğŸ›  Technologies (Partie ML)

*   **Langage** : Python 3.10+
*   **Framework** : [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) (PyTorch)
*   **Dataset** : [Bee Detection Dataset](https://www.kaggle.com/datasets/lara311/bee-detection-dataset) (Kaggle)
*   **MatÃ©riel supportÃ©** :
    *   ğŸ **MacOS (Apple Silicon)** : AccÃ©lÃ©ration via MPS (Metal Performance Shaders).
    *   ğŸªŸ **Windows / ğŸ§ Linux** : AccÃ©lÃ©ration via CUDA (NVIDIA) ou CPU.

---

## ğŸ“‚ Structure du Projet

L'organisation des fichiers pour la partie Machine Learning (`ML/`) est la suivante :

```text
mon_projet_abeilles/
â”œâ”€â”€ .venv/                 # Environnement virtuel Python
â”œâ”€â”€ ML/
â”‚   â”œâ”€â”€ datasets/          # DonnÃ©es d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ bees/
â”‚   â”‚       â”œâ”€â”€ train/     # Images & Labels d'entraÃ®nement
â”‚   â”‚       â”œâ”€â”€ val/       # Images & Labels de validation
â”‚   â”‚       â””â”€â”€ test/      # Images de test
â”‚   â”œâ”€â”€ runs/              # Logs d'entraÃ®nement et modÃ¨les sauvegardÃ©s
â”‚   â”‚   â””â”€â”€ train/
â”‚   â”‚       â””â”€â”€ bee_experiment/
â”‚   â”‚           â””â”€â”€ weights/
â”‚   â”‚               â””â”€â”€ best.pt  <-- LE MODÃˆLE FINAL
â”‚   â”œâ”€â”€ bee_data.yaml      # Configuration du dataset pour YOLO
â”‚   â”œâ”€â”€ requirements.txt   # DÃ©pendances Python
â”‚   â”œâ”€â”€ train_yolo.py      # Script d'entraÃ®nement
â”‚   â””â”€â”€ yolov8n.pt         # ModÃ¨le de base (tÃ©lÃ©chargÃ© auto.)
â””â”€â”€ README.md
```

---

## ğŸš€ Installation & Setup

Ce guide couvre Windows, MacOS et Linux.

### 1. PrÃ©requis
*   Python 3.10 ou supÃ©rieur installÃ©.
*   (Optionnel) Un compte Kaggle pour tÃ©lÃ©charger le dataset via API.

### 2. CrÃ©ation de l'environnement virtuel

Ouvrez un terminal Ã  la racine du projet `mon_projet_abeilles`.

**Sur MacOS / Linux :**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Sur Windows (PowerShell) :**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### 3. Installation des dÃ©pendances

Assurez-vous d'Ãªtre dans le dossier `ML` pour trouver le fichier requirements.

```bash
cd ML
pip install --upgrade pip
pip install -r requirements.txt
```

> **Note Mac M1/M2/M3 :** Le fichier `requirements.txt` est optimisÃ© pour installer `torch` avec le support ARM64. VÃ©rifiez que votre terminal n'utilise pas Rosetta.

---

## ğŸ“Š PrÃ©paration des DonnÃ©es

Nous utilisons le dataset "Bee Detection" de Kaggle.

1.  **TÃ©lÃ©chargement** :
    *   Via l'interface web : [Lien Kaggle](https://www.kaggle.com/datasets/lara311/bee-detection-dataset).
    *   Ou via l'API (si configurÃ©e) : `kaggle datasets download -d lara311/bee-detection-dataset`
2.  **Organisation** :
    DÃ©compressez le dataset pour obtenir la structure suivante dans `ML/datasets/bees/`. Le dataset doit contenir les dossiers `train`, `val` (et optionnellement `test`), chacun contenant `images` et `labels`.

3.  **Configuration** :
    VÃ©rifiez que le fichier `ML/bee_data.yaml` pointe bien vers ces dossiers :
    ```yaml
    path: ./datasets/bees
    train: train/images
    val: val/images
    nc: 1
    names:
        0: bee
    ```

---

## ğŸ§  Lancer l'EntraÃ®nement

Le script `train_yolo.py` lance le fine-tuning sur 50 Ã©poques avec une rÃ©solution de 640px.

**Commande :**
```bash
# Depuis le dossier ML/
python train_yolo.py
```

Le script dÃ©tectera automatiquement votre matÃ©riel :
*   `MPS` sur Mac (Apple Silicon)
*   `CUDA` sur PC (si GPU Nvidia prÃ©sent)
*   `CPU` sinon.

### RÃ©sultats
Une fois terminÃ©, les rÃ©sultats se trouvent dans `ML/runs/train/bee_experiment/` :
*   **`weights/best.pt`** : Le modÃ¨le ayant obtenu le meilleur score. **C'est ce fichier qui sera utilisÃ© pour l'application mobile.**
*   `results.csv` : Historique des mÃ©triques (pertes, prÃ©cision).

---

## ğŸ”® Prochaines Ã‰tapes

1.  Valider le modÃ¨le sur des vidÃ©os de test inÃ©dites.
2.  Convertir `best.pt` en format `.tflite`.
3.  DÃ©buter le dÃ©veloppement de l'application Android avec CameraX.
