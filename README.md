# ğŸ“± Bee Detection - Android App (Edge AI)

Ce module contient l'application **Android native** du projet Bee Detection.

C'est ici que se concrÃ©tise l'approche **Edge AI** : l'application embarque le modÃ¨le YOLOv8 entraÃ®nÃ© et quantifiÃ© pour effectuer des dÃ©tections d'abeilles en temps rÃ©el directement sur le tÃ©lÃ©phone, **sans aucune connexion internet**.

---

## ğŸ— Architecture & Workflow

Le projet global suit un pipeline en 3 Ã©tapes. Nous sommes ici Ã  l'**Ã‰tape 3**.

1.  âœ… **EntraÃ®nement (ML)** : Fine-tuning de YOLOv8 sur le dataset.
2.  âœ… **Conversion** : Export en `.tflite` avec quantification INT8 (Full Integer).
3.  ğŸš€ **IntÃ©gration Android (Ce module)** :
    * Acquisition du flux vidÃ©o via **CameraX**.
    * PrÃ©-traitement des images (Resize, Normalization).
    * InfÃ©rence locale via **TensorFlow Lite**.
    * Affichage des Bounding Boxes via **Jetpack Compose**.

---

## ğŸ›  Technologies (Partie Mobile)

* **Langage** : Kotlin
* **UI Framework** : [Jetpack Compose](https://developer.android.com/jetpack/compose) (Material 3)
* **CamÃ©ra** : [CameraX](https://developer.android.com/training/camerax) (ImageAnalysis use case)
* **ML Runtime** : TensorFlow Lite Support Library
* **Architecture** : MVVM (Model-View-ViewModel) + Clean Architecture simplifiÃ©e.

---

## ğŸ“‚ Structure du Projet

L'organisation du code source (`app/src/main/`) est la suivante :

```text
android-app/
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ yolov8n_bees_v1_full_integer_quant.tflite  # ğŸ§  Le modÃ¨le quantifiÃ©
â”œâ”€â”€ java/com/example/beedetectionapp/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ analyzer/
â”‚   â”‚   â”‚   â””â”€â”€ BeeImageAnalyzer.kt    # ğŸ“· Fait le pont entre CameraX et TFLite
â”‚   â”‚   â””â”€â”€ model/
â”‚   â”‚       â””â”€â”€ TFLiteObjectDetector.kt # ğŸ¤– GÃ¨re l'interprÃ©teur et le post-processing
â”‚   â”œâ”€â”€ domain/                        # ModÃ¨les de donnÃ©es (ex: DetectionResult)
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ BeeCard.kt             # Composants UI rÃ©utilisables
â”‚   â”‚   â”œâ”€â”€ screens/
â”‚   â”‚   â”‚   â””â”€â”€ HomeScreen.kt          # ğŸ“± Ã‰cran principal (Overlay + CamÃ©ra)
â”‚   â”‚   â””â”€â”€ theme/                     # ThÃ¨me et Couleurs
â”‚   â”œâ”€â”€ HomeViewModel.kt               # Gestion de l'Ã©tat UI
â”‚   â””â”€â”€ MainActivity.kt                # Point d'entrÃ©e de l'application
â””â”€â”€ res/                               # Ressources Android (icÃ´nes, textes...)

```

---

## ğŸš€ Installation & Setup

### 1. PrÃ©requis

* **Android Studio** (Koala ou plus rÃ©cent recommandÃ©).
* Un appareil Android physique (RecommandÃ© pour tester la camÃ©ra et les perfs ML) OU un Ã©mulateur.
* **Mode DÃ©veloppeur** activÃ© sur le tÃ©lÃ©phone.

### 2. Cloner et Ouvrir

Ouvrez le dossier `android` (ou la racine du repo si c'est un monorepo) directement dans Android Studio.

Laissez Gradle synchroniser les dÃ©pendances (`Sync Project with Gradle Files`).

### 3. Le ModÃ¨le TFLite

Le projet nÃ©cessite le fichier modÃ¨le dans le dossier `assets`.

* Si vous avez suivi la partie ML : copiez votre `best_int8.tflite` vers `app/src/main/assets/`.
* *Note : Le fichier est dÃ©jÃ  inclus dans cette branche sous le nom `yolov8n_bees_v1_full_integer_quant.tflite`.*

### 4. Lancer l'application

1. Connectez votre tÃ©lÃ©phone en USB.
2. SÃ©lectionnez votre appareil dans la barre d'outils Android Studio.
3. Cliquez sur le bouton **Run (â–¶)**.
4. Acceptez la permission CamÃ©ra au lancement.

---

## âš™ï¸ Fonctionnement Technique

### Le Pipeline d'InfÃ©rence

L'application ne traite pas chaque frame pour Ã©conomiser la batterie.

1. **Input** : CameraX fournit une image au format YUV_420_888 (ou RGBA selon config).
2. **Preprocessing** :
* L'image est redimensionnÃ©e en **640x640**.
* Conversion en `UINT8` [0-255] (Le modÃ¨le gÃ¨re la quantification interne).


3. **InfÃ©rence** : TFLite exÃ©cute le graphe du modÃ¨le.
4. **Post-processing** :
* DÃ©codage des sorties (coordonnÃ©es [x, y, w, h] et score).
* Application du **NMS (Non-Maximum Suppression)** pour Ã©viter les boÃ®tes en double.


5. **UI Update** : Les rÃ©sultats sont envoyÃ©s au `State` de Compose qui dessine les rectangles par-dessus la preview camÃ©ra.

---

## ğŸ”® Prochaines Ã‰tapes

1. Optimiser l'infÃ©rence en activant le dÃ©lÃ©guÃ© **GPU** ou **NNAPI** (Neural Networks API).
2. GÃ©rer le mode paysage (Landscape).
3. Ajouter un seuil de confiance rÃ©glable dans l'UI.
4. GÃ©nÃ©rer un APK signÃ© pour la distribution.
